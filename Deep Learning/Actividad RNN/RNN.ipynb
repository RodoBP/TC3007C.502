{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Hm_K8mxlIJ95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Allow GPU memory growth\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    \n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU available.\")\n",
        "\n",
        "# Initialize GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joisJtvjId0i"
      },
      "source": [
        "Descarga de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDFHefm3IQV9",
        "outputId": "311b2904-edae-4365-bf37-5f5324932a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del texto:    881631 caracteres\n",
            "El texto esta compuesto de estos 106 caracteres\n",
            "['\\n', '\\r', ' ', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '£', 'à', 'á', 'â', 'æ', 'è', 'é', 'ë', 'ï', 'ô', 'ö', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
          ]
        }
      ],
      "source": [
        "path_to_fileDL = tf.keras.utils.get_file('DL-Introduccion-practica-con-Keras-1a.txt', 'https://www.gutenberg.org/cache/epub/345/pg345.txt')\n",
        "\n",
        "text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n",
        "print('Longitud del texto:    {} caracteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print ('El texto esta compuesto de estos {} caracteres'.format(len(vocab)))\n",
        "print (vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdme2idzJ-AZ"
      },
      "source": [
        "Tablas de traduccion o Inversa de vocabulario\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JEmxggHLKBTO"
      },
      "outputs": [],
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTPGhiRJKkjd",
        "outputId": "a5393e9f-0531-4895-e9a2-0b341b0344a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " '\\n':   0,\n",
            " '\\r':   1,\n",
            " ' ' :   2,\n",
            " '!' :   3,\n",
            " '#' :   4,\n",
            " '$' :   5,\n",
            " '%' :   6,\n",
            " '&' :   7,\n",
            " '(' :   8,\n",
            " ')' :   9,\n",
            " '*' :  10,\n",
            " ',' :  11,\n",
            " '-' :  12,\n",
            " '.' :  13,\n",
            " '/' :  14,\n",
            " '0' :  15,\n",
            " '1' :  16,\n",
            " '2' :  17,\n",
            " '3' :  18,\n",
            " '4' :  19,\n",
            " '5' :  20,\n",
            " '6' :  21,\n",
            " '7' :  22,\n",
            " '8' :  23,\n",
            " '9' :  24,\n",
            " ':' :  25,\n",
            " ';' :  26,\n",
            " '=' :  27,\n",
            " '>' :  28,\n",
            " '?' :  29,\n",
            " 'A' :  30,\n",
            " 'B' :  31,\n",
            " 'C' :  32,\n",
            " 'D' :  33,\n",
            " 'E' :  34,\n",
            " 'F' :  35,\n",
            " 'G' :  36,\n",
            " 'H' :  37,\n",
            " 'I' :  38,\n",
            " 'J' :  39,\n",
            " 'K' :  40,\n",
            " 'L' :  41,\n",
            " 'M' :  42,\n",
            " 'N' :  43,\n",
            " 'O' :  44,\n",
            " 'P' :  45,\n",
            " 'Q' :  46,\n",
            " 'R' :  47,\n",
            " 'S' :  48,\n",
            " 'T' :  49,\n",
            " 'U' :  50,\n",
            " 'V' :  51,\n",
            " 'W' :  52,\n",
            " 'X' :  53,\n",
            " 'Y' :  54,\n",
            " 'Z' :  55,\n",
            " '[' :  56,\n",
            " ']' :  57,\n",
            " '_' :  58,\n",
            " 'a' :  59,\n",
            " 'b' :  60,\n",
            " 'c' :  61,\n",
            " 'd' :  62,\n",
            " 'e' :  63,\n",
            " 'f' :  64,\n",
            " 'g' :  65,\n",
            " 'h' :  66,\n",
            " 'i' :  67,\n",
            " 'j' :  68,\n",
            " 'k' :  69,\n",
            " 'l' :  70,\n",
            " 'm' :  71,\n",
            " 'n' :  72,\n",
            " 'o' :  73,\n",
            " 'p' :  74,\n",
            " 'q' :  75,\n",
            " 'r' :  76,\n",
            " 's' :  77,\n",
            " 't' :  78,\n",
            " 'u' :  79,\n",
            " 'v' :  80,\n",
            " 'w' :  81,\n",
            " 'x' :  82,\n",
            " 'y' :  83,\n",
            " 'z' :  84,\n",
            " '{' :  85,\n",
            " '}' :  86,\n",
            " '£' :  87,\n",
            " 'à' :  88,\n",
            " 'á' :  89,\n",
            " 'â' :  90,\n",
            " 'æ' :  91,\n",
            " 'è' :  92,\n",
            " 'é' :  93,\n",
            " 'ë' :  94,\n",
            " 'ï' :  95,\n",
            " 'ô' :  96,\n",
            " 'ö' :  97,\n",
            " '—' :  98,\n",
            " '‘' :  99,\n",
            " '’' : 100,\n",
            " '“' : 101,\n",
            " '”' : 102,\n",
            " '•' : 103,\n",
            " '™' : 104,\n",
            " '\\ufeff': 105,\n"
          ]
        }
      ],
      "source": [
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6LoNExkLJim"
      },
      "source": [
        "convertir texto a enteros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "u5Uu91VXLLKf"
      },
      "outputs": [],
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8N1RzNGLUXp",
        "outputId": "e08b9185-9ba7-433e-fbae-73c3bf7b6c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text: '\\ufeffThe Project Gutenberg eBook of Dracula\\r\\n    \\r\\nThi'\n",
            "array([105,  49,  66,  63,   2,  45,  76,  73,  68,  63,  61,  78,   2,\n",
            "        36,  79,  78,  63,  72,  60,  63,  76,  65,   2,  63,  31,  73,\n",
            "        73,  69,   2,  73,  64,   2,  33,  76,  59,  61,  79,  70,  59,\n",
            "         1,   0,   2,   2,   2,   2,   1,   0,  49,  66,  67])\n"
          ]
        }
      ],
      "source": [
        "#Mostramos algunos caracteres\n",
        "print('text: {}'.format(repr(text[:50])))\n",
        "print('{}'.format(repr(text_as_int[:50])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDdRMqTGL4es"
      },
      "source": [
        "PREPARAR DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AqLVBIzRL5dt"
      },
      "outputs": [],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAGJWcbgMexu",
        "outputId": "a135e752-5f17-41af-8002-0c7ceb5412d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'\\ufeffThe Project Gutenberg eBook of Dracula\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the Un'\n",
            "'ited States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever'\n",
            "'. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License includ'\n",
            "'ed with this ebook or online\\r\\nat www.gutenberg.org. If you are not located in the United States,\\r\\nyou'\n",
            "' will have to check the laws of the country where you are located\\r\\nbefore using this eBook.\\r\\n\\r\\nTitle:'\n",
            "' Dracula\\r\\n\\r\\n\\r\\nAuthor: Bram Stoker\\r\\n\\r\\nRelease date: October 1, 1995 [eBook #345]\\r\\n                Most'\n",
            "' recently updated: July 30, 2023\\r\\n\\r\\nLanguage: English\\r\\n\\r\\n\\r\\n\\r\\n*** START OF THE PROJECT GUTENBERG EBOOK'\n",
            "' DRACULA ***\\r\\n\\r\\n\\r\\n\\r\\n                                DRACULA\\r\\n\\r\\n                                  _by_'\n",
            "'\\r\\n\\r\\n                              Bram Stoker\\r\\n\\r\\n                        [Illustration: colophon]\\r\\n\\r\\n'\n",
            "'                                NEW YORK\\r\\n\\r\\n                            GROSSET & DUNLAP\\r\\n\\r\\n         '\n"
          ]
        }
      ],
      "source": [
        "#comprobar datos\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SSd-n7TsObPP"
      },
      "outputs": [],
      "source": [
        "#Preparar datos de entrenamiento  (Entrada 0 a 99 )  (Salida 1 a 100)\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwt86loIO3Ew",
        "outputId": "2b48fe9c-f844-4c7a-f125-8e7f1982f7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input data:  '\\ufeffThe Project Gutenberg eBook of Dracula\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the U'\n",
            "Target data:  'The Project Gutenberg eBook of Dracula\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the Un'\n"
          ]
        }
      ],
      "source": [
        "#Visualizamos\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS6s_VLoPSCB",
        "outputId": "b4c77692-9e2f-4f2b-87d9-964b122eb24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "#imprimir dataset\n",
        "print (dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUZRIbkGPiuS",
        "outputId": "b85d92c0-fc0c-475f-e394-3a0961d18621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "#agrupar en batches\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQZ_CevQAoz"
      },
      "source": [
        "Construir modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "uCCdG2uZQCQ5"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                batch_input_shape=[batch_size,None]),\n",
        "\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "                           return_sequences=True,\n",
        "                           stateful = True,\n",
        "                           recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim= 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKsclvjYypZ0",
        "outputId": "f998d048-522d-440a-942b-6c0bb2f25a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (64, None, 256)           27136     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (64, None, 106)           108650    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,382,762\n",
            "Trainable params: 5,382,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Visualizar estructura\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW-eJDbfzNIH",
        "outputId": "920dc122-272b-4ff8-90d7-d55a5c27d87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  (64, 100) # (batch_size, lenght)\n",
            "Target:  (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ],
      "source": [
        "# Forma de input\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input: \", input_example_batch.shape, \"# (batch_size, lenght)\")\n",
        "  print(\"Target: \", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbAXsYuDztDZ",
        "outputId": "702722bd-dc20-40f7-f89c-d3225a696077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:  (64, 100, 106) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "#Forma de salida\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exs9IP990Rcx",
        "outputId": "90ebba32-0735-4382-c89c-ef45d839356a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 39  46  14  58  44   4  36  99  60  99  41  58   5 102  76   7  82  66\n",
            "  28 102  41  64  25  35  36  81   0  26  22  81   5  67  43   6  87  56\n",
            "  65  45  31  77   9  80  84  95  64   8  24  94  47  10  35  97  31  53\n",
            "  62  15  93  50 101  14  30  24  94  91  46 101  30  78  30  59   5  34\n",
            " 104  74  89  94  79  72 102   0   2  69  21  80  71  67  29  67   7 102\n",
            "   6  78  71   8  11  84 102  46  48  60]\n"
          ]
        }
      ],
      "source": [
        "#Mostar que el resultado es una distribucion, no un argmax\n",
        "\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(sampled_indices_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hByCt7iq0rOm"
      },
      "source": [
        "ENTRENAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "13WGBj8X0sDs"
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ZSqhYQKh2Mgn"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_(epoch)\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-yqaDcg1Q6l",
        "outputId": "87a4484e-0a1f-4ab3-aa39-ffd57d3cb210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136/136 [==============================] - 23s 156ms/step - loss: 2.4116\n",
            "Epoch 2/10\n",
            "136/136 [==============================] - 23s 161ms/step - loss: 2.0912\n",
            "Epoch 3/10\n",
            "136/136 [==============================] - 23s 156ms/step - loss: 1.8965\n",
            "Epoch 4/10\n",
            "136/136 [==============================] - 24s 161ms/step - loss: 1.7555\n",
            "Epoch 5/10\n",
            "136/136 [==============================] - 23s 155ms/step - loss: 1.6513\n",
            "Epoch 6/10\n",
            "136/136 [==============================] - 23s 161ms/step - loss: 1.5713\n",
            "Epoch 7/10\n",
            "136/136 [==============================] - 23s 157ms/step - loss: 1.5095\n",
            "Epoch 8/10\n",
            "136/136 [==============================] - 22s 153ms/step - loss: 1.4620\n",
            "Epoch 9/10\n",
            "136/136 [==============================] - 24s 161ms/step - loss: 1.4230\n",
            "Epoch 10/10\n",
            "136/136 [==============================] - 23s 157ms/step - loss: 1.3889\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3se79_t9L_2"
      },
      "source": [
        "Generacion de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "RCqFtIqc9OQx"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Lbk-KF_v93lh"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, temp):\n",
        "  num_generate = 500\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return(start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywey-I4D_F6G",
        "outputId": "958c755f-5c1d-4f0b-c9e8-554bd20ffe90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dracula•}öè$—ö﻿ööâ>öö£öööéööööë‘”ëX﻿öööööè﻿•﻿ööö}ëöööö﻿£•öH}﻿xö﻿[﻿﻿ööööè£ööë£ë﻿ö£﻿ööööö>ööX£>öë#﻿ö£ë#ö﻿ö#‘﻿﻿öëèëëXööëööö﻿öë>ööë‘}#öööâöëö#öö﻿﻿﻿öö﻿öö#è[öööè£èö﻿ö>öâ[ö£﻿öëö﻿éööèè™‘àöë•&ö}£öö>﻿öè—öè﻿öà>ö&‘ö﻿áö—ö£ëëöööëö#ë‘—ï﻿﻿ö£öë£ö﻿﻿X£[﻿öö#ö*™ëëëF}ö0ö£ö>ö$ö﻿﻿öâ£﻿ö#öö﻿öëö}öXëö}öö﻿﻿ë﻿ëöö—ö﻿âöëXöæèö﻿ëXé>öë]öö﻿ë>#öö﻿ö[öö﻿﻿﻿öâööö﻿﻿﻿﻿ëX—}ëöèöööZë>è﻿﻿èëöëö‘âö﻿﻿öáöXö﻿ö﻿ööööö﻿ö﻿﻿﻿è™öëööá>﻿éö﻿”>öëööööö([Xööà﻿﻿ë—ë﻿ö}éöö﻿#ö﻿ö]}ëáöööööè﻿è﻿ö}öëXö—ë﻿ööXö﻿﻿ëöèöö﻿ë﻿ö﻿âö•‘%﻿ëööö™>à‘}é[ö﻿è﻿ööxö﻿öööööö﻿ö﻿﻿ö﻿﻿ëëöö—™>£öö﻿ö﻿é﻿\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Dracula\", temp=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJZ1jcp-_UM9",
        "outputId": "66415911-6121-4d5d-e7ba-5c89d8d8bf62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dracula[£ë‘﻿]ö‘™™èëöööö£âö>£﻿ö﻿öö£ëöj£﻿ö(>﻿éëööéö™ö—ö%[ö﻿ëX﻿ö”>£ëï#£èX[$﻿﻿ö£â[èöë#﻿£âàëjö%‘%£â&‘öâë‘Z($[0ë‘0z﻿ö}>>ö(—xïö﻿ö0ö•ë‘èZè#àZöë}ö0è﻿#﻿ôè﻿>ë*ö•[é}éö[öëöö﻿ööëX[ö﻿ö﻿ô£ö•é‘àëDöæ£ëïöëZ﻿ë9#ö£ö﻿èöà&>﻿ë}ëïZ•ëöëâë‘öéö£èëâëà﻿è”﻿x>ëëö﻿﻿ë}#﻿}£•èö﻿ë#ö£èö£é﻿öö£*xöé>>﻿ëö[Zëöj}ëZööà>>£ö—é}ô﻿ëöX•£ëö0>ö•öï﻿é﻿%*$ö#Zë£ö﻿ëö—{™éö}ë>>>&öâö[﻿öö£ëï#ë#)ë—èàXXö﻿9ë﻿ö£Zöàëö﻿7â™W£xö9öëèöZ&öà&‘àö﻿ë*>#﻿0*>è[0â>öéè#﻿}ë£ëj﻿âè}é>ï•ë}&ë﻿xö##>ö%#}ë[è™ëö£>ö[ööö”﻿﻿﻿è[öXöëö﻿âZö%ö﻿%‘(>£•*âööëöéö4YöXöö﻿*ââéö)ö﻿ë&&£&öx>>$Z﻿ööââö﻿èô—â—>&\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Dracula\", temp=0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE-rdd8X_Zbm",
        "outputId": "bfa7dda1-0aee-476a-ee3c-7232a47ccc57"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\luisr\\OneDrive\\Documentos\\AI 2\\Estadistica Avanzada\\RNN.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(generate_text(model, start_string\u001b[39m=\u001b[39;49m\u001b[39mu\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDracula\u001b[39;49m\u001b[39m\"\u001b[39;49m, temp\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m))\n",
            "\u001b[1;32mc:\\Users\\luisr\\OneDrive\\Documentos\\AI 2\\Estadistica Avanzada\\RNN.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mreset_states()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_generate):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   predictions \u001b[39m=\u001b[39m model(input_eval)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   predictions \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msqueeze(predictions,\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luisr/OneDrive/Documentos/AI%202/Estadistica%20Avanzada/RNN.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   predictions \u001b[39m=\u001b[39m predictions\u001b[39m/\u001b[39mtemperature\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\sequential.py:410\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m    409\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)\n\u001b[1;32m--> 410\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m    412\u001b[0m outputs \u001b[39m=\u001b[39m inputs  \u001b[39m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m    414\u001b[0m     \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     \u001b[39m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[39m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[39m# the next layer.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 667\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    669\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    671\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    672\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py:553\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[0;32m    549\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[0;32m    550\u001b[0m )\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    555\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:733\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[39m# Under eager context, check the device placement and prefer\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[39m# the GPU implementation when GPU is available.\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39mif\u001b[39;00m can_use_gpu:\n\u001b[1;32m--> 733\u001b[0m     last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m gpu_lstm(\n\u001b[0;32m    734\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgpu_lstm_kwargs\n\u001b[0;32m    735\u001b[0m     )\n\u001b[0;32m    736\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    737\u001b[0m     (\n\u001b[0;32m    738\u001b[0m         last_output,\n\u001b[0;32m    739\u001b[0m         outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    742\u001b[0m         runtime,\n\u001b[0;32m    743\u001b[0m     ) \u001b[39m=\u001b[39m standard_lstm(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py:1151\u001b[0m, in \u001b[0;36mgpu_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, return_sequences)\u001b[0m\n\u001b[0;32m   1149\u001b[0m last_output \u001b[39m=\u001b[39m outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m   1150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m time_major \u001b[39mand\u001b[39;00m sequence_lengths \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m return_sequences:\n\u001b[1;32m-> 1151\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtranspose(outputs, perm\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m])\n\u001b[0;32m   1152\u001b[0m h \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msqueeze(h, axis\u001b[39m=\u001b[39mseq_axis)\n\u001b[0;32m   1153\u001b[0m c \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msqueeze(c, axis\u001b[39m=\u001b[39mseq_axis)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2285\u001b[0m, in \u001b[0;36mtranspose_v2\u001b[1;34m(a, perm, conjugate, name)\u001b[0m\n\u001b[0;32m   2207\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   2208\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   2209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranspose_v2\u001b[39m(a, perm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, conjugate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtranspose\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2210\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Transposes `a`, where `a` is a Tensor.\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m \n\u001b[0;32m   2212\u001b[0m \u001b[39m  Permutes the dimensions according to the value of `perm`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2283\u001b[0m \u001b[39m    A transposed `Tensor`.\u001b[39;00m\n\u001b[0;32m   2284\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2285\u001b[0m   \u001b[39mreturn\u001b[39;00m transpose(a\u001b[39m=\u001b[39;49ma, perm\u001b[39m=\u001b[39;49mperm, name\u001b[39m=\u001b[39;49mname, conjugate\u001b[39m=\u001b[39;49mconjugate)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2366\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   2363\u001b[0m   transpose_fn \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39mtranspose\n\u001b[0;32m   2365\u001b[0m \u001b[39mif\u001b[39;00m perm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2366\u001b[0m   \u001b[39mreturn\u001b[39;00m transpose_fn(a, perm, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2368\u001b[0m rank \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m   2369\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:11881\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  11879\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m  11880\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m> 11881\u001b[0m   \u001b[39mreturn\u001b[39;00m transpose_eager_fallback(\n\u001b[0;32m  11882\u001b[0m       x, perm, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m  11883\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m  11884\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:11906\u001b[0m, in \u001b[0;36mtranspose_eager_fallback\u001b[1;34m(x, perm, name, ctx)\u001b[0m\n\u001b[0;32m  11904\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [x, perm]\n\u001b[0;32m  11905\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTperm\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tperm)\n\u001b[1;32m> 11906\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTranspose\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat,\n\u001b[0;32m  11907\u001b[0m                            attrs\u001b[39m=\u001b[39;49m_attrs, ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  11908\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[0;32m  11909\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[0;32m  11910\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mTranspose\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
            "File \u001b[1;32mc:\\Users\\luisr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(generate_text(model, start_string=u\"Dracula\", temp=1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(generate_text(model, start_string=u\"song\", temp=0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(generate_text(model, start_string=u\"song\", temp=0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(generate_text(model, start_string=u\"song\", temp=1.0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
